{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flowdec.nb import utils as nbutils \n",
    "from flowdec import data as fd_data\n",
    "# import pims\n",
    "# import pims\n",
    "from flowdec import restoration as fd_restoration\n",
    "from flowdec import data as fd_data\n",
    "from flowdec import psf as fd_psf\n",
    "import dask\n",
    "import dask.array as da\n",
    "import tifffile as tf\n",
    "from nd2reader import ND2Reader\n",
    "# from pims import ND2_Reader \n",
    "# import aicsimageio.vendor.omexml as ome\n",
    "import glob\n",
    "import time, sys\n",
    "sys.path.insert(0,'./libraries/')\n",
    "from deco_libraries import update_progress, pimsmeta2OMEXML, Nd2meta2OMEXML, observer, init_RL_algo, deconv, depth_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_Metilin_RFP670.nd2', '/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_NOMetilin_RFP670 .nd2']\n",
      "/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_Metilin_RFP670.nd2\n",
      "{'x': 2048, 'y': 2048, 'c': 3, 't': 1, 'z': 9, 'v': 8}\n",
      "['FITC', 'TRITC', 'Cy5']\n"
     ]
    }
   ],
   "source": [
    "#THINGS TO CHANGE!!!!! Always keep /*.nd2 at the end\n",
    "#For gui make a function with all this input for verification purposes when loading the files\n",
    "# dirname = \"D:/Stephanie/20210203Livecaru/*nd2\"\n",
    "# dirname = \"D:/JM/csbdeeptraining/GT/*nd2\"\n",
    "dirname = \"/run/media/jmamede/Joao/CAruby/mellitin/*.nd2\"\n",
    "\n",
    "\n",
    "filelist = glob.glob(dirname)\n",
    "filelist.sort()\n",
    "# filelist.pop()\n",
    "# filelist = filelist[2:3]\n",
    "\n",
    "print(filelist)\n",
    "print(filelist[0])\n",
    "#Load the first file for reference and what's inside the file\n",
    "frames = ND2Reader(filelist[0])\n",
    "print(frames.sizes)\n",
    "#Grab metadata\n",
    "metadata = frames.metadata\n",
    "print(metadata['channels'])\n",
    "\n",
    "#If you don't have enough VRAM divide the XY to do the deconvolution that is automatically assembled after\n",
    "xdivide = 1\n",
    "ydivide = 1\n",
    "depthdivide = depth_divide(xdivide, ydivide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filelist.pop(1)\n",
    "# filelist.pop(1)\n",
    "# filelist\n",
    "# test = filelist.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 256, 256)\n",
      "(9, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#Need to make this a big more automatic, but indexing all the files and iterations is not easy\n",
    "#In the version where the PSF is estimated by flowdec is easier because everything was set to automatic\n",
    "\n",
    "\n",
    "PSFdir=\"/home/jmamede/Rush/PSF/\"\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.3_EMCCD.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.3_EMCCD.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.3_EMCCD.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI_0.3_EMCCD.tif')\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.5_EMCCD.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.5_EMCCD.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.5_EMCCD.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI_0.5_EMCCD.tif')\n",
    "psf647 = tf.imread(PSFdir+\"/AF647.tif\")\n",
    "psfruby =  tf.imread(PSFdir+'/mRuby3.tif')\n",
    "psfgfp =  tf.imread(PSFdir+'/green.tif')\n",
    "psfdapi =  tf.imread(PSFdir+'/DAPI.tif')\n",
    "# psfruby = psf647\n",
    "# psfgfp = psf647\n",
    "# psfdapi = psf647\n",
    "\n",
    "#Clip Top and bottom, I found that if the PSF is calculated with distance from coverslip, it is flipped from Fiji\n",
    "#As in, it is Top to Bottom, I acquire the images Bottom to Top\n",
    "# remove = 1\n",
    "\n",
    "remove = 13\n",
    "psf647 = np.flip(psf647,\n",
    "#                  axis=0\n",
    "                )[remove:-remove,...]\n",
    "\n",
    "psfgfp = np.flip(psfgfp,\n",
    "#                  axis=0\n",
    "                )[remove:-remove,...]\n",
    "psfdapi = np.flip(psfdapi,\n",
    "#                   axis=0\n",
    "                 )[remove:-remove,...]\n",
    "psfruby = np.flip(psfruby,\n",
    "#                   axis=0\n",
    "                 )[remove:-remove,...]\n",
    "\n",
    "print(psf647.shape)\n",
    "print(psfruby.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_Metilin_RFP670.nd2', '/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_NOMetilin_RFP670 .nd2']\n",
      "['/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_Metilin_RFP670.nd2', '/run/media/jmamede/Joao/CAruby/mellitin/iGFP_optiR3_050621_NOMetilin_RFP670 .nd2']\n"
     ]
    }
   ],
   "source": [
    "algo =init_RL_algo(psfgfp.ndim\n",
    "                   ,pad_mode='2357',pad_min=(2,12,12)\n",
    "#                    ,pad_mode='log2',pad_min=(2,12,12)\n",
    "#                    ,pad_mode='None',pad_min=(0,0,0)                   \n",
    "                  )\n",
    "print(filelist)\n",
    "fname2 = filelist[1]\n",
    "fname1 = filelist[0]\n",
    "# filelist.pop(0)\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5287662347157797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# frames.parser._raw_metadata.image_metadata\n",
    "def get_deltaT(filename1,filename2):\n",
    "    \n",
    "    import pathlib\n",
    "\n",
    "    fname1 = pathlib.Path(filename1)\n",
    "    fname2 = pathlib.Path(filename2)\n",
    "    import datetime\n",
    "    mtime2 = datetime.datetime.fromtimestamp(fname2.stat().st_ctime)\n",
    "    mtime1 = datetime.datetime.fromtimestamp(fname1.stat().st_ctime)\n",
    "#     print(mtime2,mtime1)\n",
    "#     print(fname2.stat().st_ctime - fname1.stat().st_ctime)\n",
    "    return fname2.stat().st_ctime - fname1.stat().st_ctime\n",
    "    # time_offset = 71146.03463482857\n",
    "    \n",
    "print(get_deltaT(fname1,fname2)/60)\n",
    "\n",
    "time_offset = get_deltaT(fname1,fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FramesSequenceND>\n",
       "Axes: 6\n",
       "Axis 'x' size: 1024\n",
       "Axis 'y' size: 1024\n",
       "Axis 'c' size: 3\n",
       "Axis 't' size: 1\n",
       "Axis 'z' size: 23\n",
       "Axis 'v' size: 20\n",
       "Pixel Datatype: <class 'numpy.float64'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames =  ND2Reader(filelist[1])\n",
    "# flip_channels = [-1]\n",
    "# flip_channels = [63, 64, 65, 66, 67]\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "savePRJ = True\n",
    "saveStack = False\n",
    "# time_offset = 0\n",
    "# maxT = 25\n",
    "maxT = None\n",
    "concattime = False\n",
    "for fname in filelist:\n",
    "    #to add the real time of experiment when we have to split it into different files\n",
    "    if concattime:\n",
    "#         time_offset = get_deltaT(filelist[0],fname)\n",
    "        time_offset = get_deltaT(fname1,fname)\n",
    "    else: time_offset = 0\n",
    "    frames =  ND2Reader(fname)\n",
    "    frames.iter_axes = 't'  # 't' is the default already\n",
    "    frames.bundle_axes = 'zyx'  # when 'z' is available, this will be default\n",
    "\n",
    "    channels = frames.metadata['channels']\n",
    "    metadata = frames.metadata\n",
    "    if saveStack:\n",
    "        xml = Nd2meta2OMEXML(frames,time_offset=time_offset, maxT=maxT)\n",
    "    if savePRJ:\n",
    "        prjxml = Nd2meta2OMEXML(frames, project=True,time_offset=time_offset, maxT=maxT)\n",
    "\n",
    "    chunk_size=(frames.sizes['z'],frames.sizes['y']//ydivide,frames.sizes['x']//xdivide)\n",
    "\n",
    "    # frames.iter_axes = 'v'\n",
    "    # for frame in frames:\n",
    "    for visit in range(frames.sizes['v']):\n",
    "#     for visit in range(21,31):\n",
    "\n",
    "        frames.default_coords['v'] = visit\n",
    "        stackfile = fname[:-4]+\"_v\"+str(visit+1).zfill(2)+'.ome.tiff'\n",
    "        prjfile = fname[:-4]+\"_v\"+str(visit+1).zfill(2)+'_PRJ.ome.tiff'\n",
    "        if saveStack:\n",
    "            tifstack = tf.TiffWriter(stackfile, bigtiff=False,imagej=False)\n",
    "            firststk = True\n",
    "        if savePRJ:\n",
    "            tifprj = tf.TiffWriter(prjfile, bigtiff=False, imagej=False)\n",
    "            first = True\n",
    "        if maxT == None:\n",
    "            counterT = frames.sizes['t']\n",
    "        else: counterT = maxT\n",
    "            \n",
    "            \n",
    "        for time in range(counterT):\n",
    "#         for time in range(25):\n",
    "\n",
    "            res = np.zeros(\n",
    "                (frames.sizes['z'],frames.sizes['c']\n",
    "                 ,frames.sizes['y'],frames.sizes['x'])\n",
    "                , dtype=np.float32)\n",
    "            for i in range(frames.sizes['c']):\n",
    "                frames.default_coords['c'] = i\n",
    "#                     print('Channel:',metadata['channels'][i])\n",
    "                ch = metadata['channels'][i]\n",
    "                # ['a647', 'DAPI', 'GFP']\n",
    "                # ['FITC', 'mRuby3', 'miRFP670']\n",
    "                # ['FRET-gYFP-dsRED', 'mRuby', 'GFP', 'DAPI']\n",
    "                # ['a647', 'DAPI', 'GFP']\n",
    "                if ch == 'DAPI' or ch  == '470 nm':\n",
    "                    psf = psfdapi\n",
    "                elif ch == 'miRFP670' or ch == 'a647' or ch == 'mirfp670' or ch == 'farRED-EM':\n",
    "                    psf = psf647\n",
    "                elif ch == 'GFP' or ch == 'FITC'  or ch == 'GREEN-EM' or ch == 'FITC (Em)':\n",
    "                    psf = psfgfp\n",
    "                elif ch == 'mRuby3' or ch == 'mRuby' or ch ==  '555 nm' or ch == 'RED-EM':\n",
    "                    psf = psfruby\n",
    "                elif ch == 'FRET-gYFP-dsRED':\n",
    "                    psf = psfruby\n",
    "                else: psf = psfruby\n",
    "\n",
    "                arr = da.from_array(frames[time]           \n",
    "                                    , chunks=chunk_size)\n",
    "\n",
    "\n",
    "                res[:,i,:,:] = da.map_overlap(deconv,arr, depth  = depthdivide ,boundary='reflect',\n",
    "                                    dtype='float32', algo=algo,\n",
    "                                    psf=psf, iters=100, use_ram=False\n",
    "                                             ).compute(num_workers=1)\n",
    "\n",
    "                # If we need to swap Channel and Z in the future\n",
    "                #             img5d = np.swapaxes(img5d,0,1)\n",
    "\n",
    "                update_progress( (visit+1) * (time+1) / (frames.sizes['v']* counterT) )\n",
    "                print(\"Visit Point: {}/{} \\t Time:{}/{} \\t Channel:{}/{}\".format(\n",
    "                        visit+1, frames.sizes['v']\n",
    "                        ,time+1,  counterT\n",
    "                        , i+1, frames.sizes['c']))\n",
    "# Make Function\n",
    "            if saveStack:\n",
    "\n",
    "                if firststk:\n",
    "                    tifstack.save(res.astype(np.uint16),\n",
    "                        compress='ZLIB',\n",
    "                        description = xml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "                    firststk = False\n",
    "                else:\n",
    "                    tifstack.save(res.astype(np.uint16),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "#                         datetime= True,\n",
    "                        photometric='minisblack',\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "            if savePRJ:\n",
    "                if first:\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0),\n",
    "                        compress='ZLIB',\n",
    "                        description = prjxml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        #, datetime= True\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "                    first = False\n",
    "                else:                  \n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        #, datetime= True\n",
    "                        metadata= None,\n",
    "                        contiguous=False,\n",
    "                        )\n",
    "        if saveStack:\n",
    "            tifstack.close()\n",
    "        if savePRJ:\n",
    "            tifprj.close()\n",
    "\n",
    "    update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x000001FE00E25368 to Device at 0x000001FE009A1BC8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('done')\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "#the memory was released here!\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buh\r\n"
     ]
    }
   ],
   "source": [
    "!echo 'buh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error org.freedesktop.DBus.Error.ServiceUnknown: The name org.freedesktop.ConsoleKit was not provided by any .service files\r\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/dbus-send --system --print-reply --dest=\"org.freedesktop.ConsoleKit\" /org/freedesktop/ConsoleKit/Manager org.freedesktop.ConsoleKit.Manager.Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"shutdown /s /\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
