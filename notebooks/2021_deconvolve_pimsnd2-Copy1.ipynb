{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4cce51ced277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pims' is not defined"
     ]
    }
   ],
   "source": [
    "pims.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flowdec.nb import utils as nbutils \n",
    "from flowdec import data as fd_data\n",
    "import pims\n",
    "from pims import ND2_Reader\n",
    "# import pims\n",
    "from flowdec import restoration as fd_restoration\n",
    "from flowdec import data as fd_data\n",
    "from flowdec import psf as fd_psf\n",
    "import dask\n",
    "import dask.array as da\n",
    "import tifffile as tf\n",
    "# from nd2reader import ND2Reader\n",
    "# from pims import ND2_Reader as ND2Reader\n",
    "# import aicsimageio.vendor.omexml as ome\n",
    "import glob\n",
    "import time, sys\n",
    "sys.path.insert(0,'./libraries/')\n",
    "from deco_libraries import update_progress, pims_nd2meta2OMEXML, observer, init_RL_algo, deconv, depth_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"/home/jmamede/imscope/JM/2020/20200626/igfp1_caruby5_continue001trigger002.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jmamede/imscope/JM/2020/20200626/igfp1_caruby5_continue001trigger002.nd2']\n",
      "/home/jmamede/imscope/JM/2020/20200626/igfp1_caruby5_continue001trigger002.nd2\n",
      "{'x': 2048, 'y': 2044, 'c': 3, 't': 67, 'm': 31, 'z': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/pims/base_frames.py:472: UserWarning: Please call FramesSequenceND.__init__() at the start of thethe reader initialization.\n",
      "  warn(\"Please call FramesSequenceND.__init__() at the start of the\"\n"
     ]
    }
   ],
   "source": [
    "#THINGS TO CHANGE!!!!! Always keep /*.nd2 at the end\n",
    "#For gui make a function with all this input for verification purposes when loading the files\n",
    "# dirname = \"/run/user/1000/gvfs/smb-share:server=rup-isilon100.rush.edu,share=user/J/jmamede/BigData/Stephanie/M15d_iGFPCAru3_01062021_PBN_VitC_Rutin_NH4Cl_nuc_Vera_pump.nd2\"\n",
    "# dirname = \"D:/Stephanie/20210408MDM/*.nd2\"\n",
    "# dirname = \"D:/JM/20201222caru3/Carubyigfp_F2_Nh4cl_vitc_rutin_BVD002.nd2\"\n",
    "\n",
    "\n",
    "filelist = glob.glob(dirname)\n",
    "filelist.sort()\n",
    "# filelist.pop(1)\n",
    "\n",
    "print(filelist)\n",
    "print(filelist[0])\n",
    "#Load the first file for reference and what's inside the file\n",
    "frames =  pims.open(filelist[0])\n",
    "print(frames.sizes)\n",
    "#Grab metadata\n",
    "metadata = frames.metadata\n",
    "# print(metadata['channels'])\n",
    "\n",
    "#If you don't have enough VRAM divide the XY to do the deconvolution that is automatically assembled after\n",
    "xdivide = 2\n",
    "ydivide = 2\n",
    "depthdivide = depth_divide(xdivide, ydivide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.metadata_text\n",
    "# test = filelist.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 128, 128)\n",
      "(19, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#Need to make this a big more automatic, but indexing all the files and iterations is not easy\n",
    "#In the version where the PSF is estimated by flowdec is easier because everything was set to automatic\n",
    "\n",
    "PSFdir=\"/home/jmamede/Rush/PSF/\"\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.3_EMCCD.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.3_EMCCD.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.3_EMCCD.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI_0.3_EMCCD.tif')\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.5_EMCCD.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.5_EMCCD.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.5_EMCCD.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI_0.5_EMCCD.tif')\n",
    "psf647 = tf.imread(PSFdir+\"/AF647.tif\")\n",
    "psfruby =  tf.imread(PSFdir+'/mRuby3.tif')\n",
    "psfgfp =  tf.imread(PSFdir+'/green.tif')\n",
    "psfdapi =  tf.imread(PSFdir+'/DAPI.tif')\n",
    "# psfruby = psf647\n",
    "# psfgfp = psf647\n",
    "# psfdapi = psf647\n",
    "\n",
    "#Clip Top and bottom, I found that if the PSF is calculated with distance from coverslip, it is flipped from Fiji\n",
    "#As in, it is Top to Bottom, I acquire the images Bottom to Top\n",
    "remove = 8\n",
    "# remove = 14\n",
    "psf647 = np.flip(psf647,\n",
    "#                  axis=0\n",
    "                )[remove:-remove,64:-64,64:-64]\n",
    "\n",
    "psfgfp = np.flip(psfgfp,\n",
    "#                  axis=0\n",
    "                )[remove:-remove,64:-64,64:-64]\n",
    "psfdapi = np.flip(psfdapi,\n",
    "#                   axis=0\n",
    "                 )[remove:-remove,64:-64,64:-64]\n",
    "psfruby = np.flip(psfruby,\n",
    "#                   axis=0\n",
    "                 )[remove:-remove,64:-64,64:-64]\n",
    "\n",
    "print(psf647.shape)\n",
    "print(psfruby.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jmamede/imscope/JM/2020/20200626/igfp1_caruby5_continue001trigger002.nd2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo =init_RL_algo(psfgfp.ndim\n",
    "                   ,pad_mode='2357',pad_min=(2,24,24)\n",
    "#                    ,pad_mode='log2',pad_min=(1,1,1)\n",
    "                  )\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname2 = filelist[3]\n",
    "# fname1 = filelist[0]\n",
    "# # frames.parser._raw_metadata.image_metadata\n",
    "# def get_deltaT(filename1,filename2):\n",
    "    \n",
    "#     import pathlib\n",
    "\n",
    "#     fname1 = pathlib.Path(filename1)\n",
    "#     fname2 = pathlib.Path(filename2)\n",
    "#     import datetime\n",
    "#     mtime2 = datetime.datetime.fromtimestamp(fname2.stat().st_ctime)\n",
    "#     mtime1 = datetime.datetime.fromtimestamp(fname1.stat().st_ctime)\n",
    "# #     print(mtime2,mtime1)\n",
    "# #     print(fname2.stat().st_ctime - fname1.stat().st_ctime)\n",
    "#     return fname2.stat().st_ctime - fname1.stat().st_ctime\n",
    "#     # time_offset = 71146.03463482857\n",
    "    \n",
    "# print(get_deltaT(fname1,fname2)/60)\n",
    "\n",
    "# time_offset = get_deltaT(fname1,fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [--------------------] 0.3%\n",
      "Visit Point: 1/31 \t Time:6/67 \t Channel:1/3\n"
     ]
    }
   ],
   "source": [
    "savePRJ = True\n",
    "saveStack = False\n",
    "# time_offset = 0\n",
    "# maxT = 25\n",
    "maxT = None\n",
    "concattime = False\n",
    "for fname in filelist:\n",
    "    #to add the real time of experiment when we have to split it into different files\n",
    "    if concattime:\n",
    "#         time_offset = get_deltaT(filelist[0],fname)\n",
    "        time_offset = get_deltaT(fname1,fname)\n",
    "    else: time_offset = 0\n",
    "    frames =  pims.open(fname)\n",
    "    frames.iter_axes = 't'  # 't' is the default already\n",
    "    frames.bundle_axes = 'zyx'  # when 'z' is available, this will be default\n",
    "    \n",
    "    channels = [frames.metadata['plane_0']['name'],frames.metadata['plane_1']['name'],frames.metadata['plane_2']['name']]\n",
    "#     channels = frames.metadata['channels']\n",
    "\n",
    "    metadata = frames.metadata\n",
    "#     if saveStack:\n",
    "#         xml = pims_nd2meta2OMEXML(frames,time_offset=time_offset, maxT=maxT)\n",
    "#     if savePRJ:\n",
    "#         prjxml = pims_nd2meta2OMEXML(frames, project=True,time_offset=time_offset, maxT=maxT)\n",
    "\n",
    "    chunk_size=(frames.sizes['z'],frames.sizes['y']//ydivide,frames.sizes['x']//xdivide)\n",
    "\n",
    "    # frames.iter_axes = 'v'\n",
    "    # for frame in frames:\n",
    "    for visit in range(frames.sizes['m']):\n",
    "#     for visit in range(21,31):\n",
    "\n",
    "        frames.default_coords['m'] = visit\n",
    "        stackfile = fname[:-4]+\"_v\"+str(visit+1).zfill(2)+'.tiff'\n",
    "        prjfile = fname[:-4]+\"_v\"+str(visit+1).zfill(2)+'_PRJ.tiff'\n",
    "        \n",
    "        if saveStack:\n",
    "            tifstack = tf.TiffWriter(stackfile, bigtiff=False,imagej=False)\n",
    "            firststk = True\n",
    "        if savePRJ:\n",
    "            tifprj = tf.TiffWriter(prjfile, bigtiff=False, imagej=False)\n",
    "            first = True\n",
    "            \n",
    "        if maxT == None:\n",
    "            counterT = frames.sizes['t']\n",
    "        else: counterT = maxT\n",
    "        for time in range(counterT):\n",
    "#         for time in range(25):\n",
    "\n",
    "            res = np.zeros(\n",
    "                (frames.sizes['z'],frames.sizes['c']\n",
    "                 ,frames.sizes['y'],frames.sizes['x'])\n",
    "                , dtype=np.float32)\n",
    "            for i in range(frames.sizes['c']):\n",
    "                frames.default_coords['c'] = i\n",
    "#                     print('Channel:',metadata['channels'][i])\n",
    "                ch = frames.metadata['plane_'+str(i)]['name']\n",
    "                # ['a647', 'DAPI', 'GFP']\n",
    "                # ['FITC', 'mRuby3', 'miRFP670']\n",
    "                # ['FRET-gYFP-dsRED', 'mRuby', 'GFP', 'DAPI']\n",
    "                # ['a647', 'DAPI', 'GFP']\n",
    "                if ch == 'DAPI' or ch  == '470 nm':\n",
    "                    psf = psfdapi\n",
    "                elif ch == 'miRFP670' or ch == 'a647' or ch == 'mirfp670' or ch == 'farRED-EM':\n",
    "                    psf = psf647\n",
    "                elif ch == 'GFP' or ch == 'FITC'  or ch == 'GREEN-EM' or ch == 'FITC (Em)':\n",
    "                    psf = psfgfp\n",
    "                elif ch == 'mRuby3' or ch == 'mRuby' or ch ==  '555 nm' or ch == 'RED-EM':\n",
    "                    psf = psfruby\n",
    "                elif ch == 'FRET-gYFP-dsRED':\n",
    "                    psf = psfruby\n",
    "                else: psf = psfruby\n",
    "\n",
    "                arr = da.from_array(frames[time]           \n",
    "                                    , chunks=chunk_size)\n",
    "\n",
    "\n",
    "                res[:,i,:,:] = da.map_overlap(deconv,arr, depth  = depthdivide ,boundary='reflect',\n",
    "                                    dtype='float32', algo=algo,\n",
    "                                    psf=psf, iters=100,\n",
    "                                    use_ram=True,\n",
    "                                            \n",
    "                                             ).compute(num_workers=1)\n",
    "\n",
    "                # If we need to swap Channel and Z in the future\n",
    "                #             img5d = np.swapaxes(img5d,0,1)\n",
    "\n",
    "                update_progress( (visit+1) * (time+1) / (frames.sizes['m']* counterT) )\n",
    "                print(\"Visit Point: {}/{} \\t Time:{}/{} \\t Channel:{}/{}\".format(\n",
    "                        visit+1, frames.sizes['m']\n",
    "                        ,time+1,  counterT\n",
    "                        , i+1, frames.sizes['c']))\n",
    "# Make Function\n",
    "            if saveStack:\n",
    "\n",
    "                if firststk:\n",
    "                    tifstack.save(res.astype(np.uint16),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "                    firststk = False\n",
    "                    print('blup')\n",
    "                else:\n",
    "                    tifstack.save(res.astype(np.uint16),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "#                         datetime= True,\n",
    "                        photometric='minisblack',\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "            if savePRJ:\n",
    "                if first:\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0),\n",
    "                        compress='ZLIB',\n",
    "#                         description = prjxml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        #, datetime= True\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "                    first = False\n",
    "                else:\n",
    "                    \n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        #, datetime= True\n",
    "                        metadata= None,\n",
    "                        contiguous=False,\n",
    "                        )\n",
    "        if saveStack:\n",
    "            tifstack.close()\n",
    "        if savePRJ:\n",
    "            tifprj.close()\n",
    "\n",
    "    update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x0000027EF3C12C78 to Device at 0x0000027EF24E52C8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('done')\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "#the memory was released here!\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
