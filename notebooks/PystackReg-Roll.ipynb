{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import pims\n",
    "# from nd2reader import ND2Reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/home/jmamede/scripts')\n",
    "# from support_pla import othercolor, cell_mask, multiply, rebin\n",
    "from support_pla import convert16to8bits\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from pystackreg import StackReg\n",
    "# from skimage import io\n",
    "\n",
    "def rebin(arr, new_shape):\n",
    "    from PIL import Image\n",
    "    return np.array(Image.fromarray(arr).resize(new_shape,resample=Image.NEAREST))\n",
    "\n",
    "def calculate_reg(ref,mov,name):\n",
    "    from pystackreg import StackReg\n",
    "    transformations = {\n",
    "        'TRANSLATION': StackReg.TRANSLATION,\n",
    "        'RIGID_BODY': StackReg.RIGID_BODY,\n",
    "        'SCALED_ROTATION': StackReg.SCALED_ROTATION,\n",
    "        'AFFINE': StackReg.AFFINE,\n",
    "        'BILINEAR': StackReg.BILINEAR\n",
    "    }\n",
    "    sr = StackReg(transformations[name])\n",
    "    return sr,sr.register(ref, mov,)\n",
    "\n",
    "def registration(image,tmat,name='AFFINE'):\n",
    "    from pystackreg import StackReg\n",
    "    from skimage import transform, io, exposure\n",
    "    transformations = {\n",
    "        'TRANSLATION': StackReg.TRANSLATION,\n",
    "        'RIGID_BODY': StackReg.RIGID_BODY,\n",
    "        'SCALED_ROTATION': StackReg.SCALED_ROTATION,\n",
    "        'AFFINE': StackReg.AFFINE,\n",
    "        'BILINEAR': StackReg.BILINEAR\n",
    "    }\n",
    "    sr = StackReg(transformations[name])\n",
    "    return sr.transform(image,tmat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficheiros = glob('/run/media/jmamede/Joao/multiplex/ENDO/out/final_c*tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/run/media/jmamede/Joao/multiplex/ENDO/out/final_c00.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c01.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c02.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c03.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c04.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c05.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c06.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c07.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c08.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c09.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c10.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c11.tiff',\n",
       " '/run/media/jmamede/Joao/multiplex/ENDO/out/final_c12.tiff']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ficheiros.sort()\n",
    "ficheiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mov' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-50d0d06b26cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# a = pims.open(ficheiros[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mov' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19759, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'mov' at 0x7f3eb417a810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pims.open(ficheiros[0])[3]\n",
    "mov = pims.open(ficheiros[1])[3]\n",
    "# len(a)\n",
    "import napari\n",
    "v = napari.Viewer(ndisplay=2)\n",
    "mov = np.roll(mov,-2305,axis=1)\n",
    "mov = np.roll(mov,100,axis=0)\n",
    "v.add_image(ref,blending='additive',colormap='green')\n",
    "v.add_image(mov,blending='additive',colormap='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import napari\n",
    "# v = napari.Viewer(ndisplay=2)\n",
    "\n",
    "# # v.add_image(ref1,blending='additive',colormap='green')\n",
    "# # v.add_image(mov1,blending='additive',colormap='red')\n",
    "# # v.add_image(test1,blending='additive',colormap='cyan')\n",
    "\n",
    "# for _file in ficheiros:\n",
    "#     a = pims.open(_file)\n",
    "#     for i in range(len(a)):\n",
    "#         v.add_image(a[i],blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load reference and \"moved\" image\n",
    "ref = pims.open(ficheiros[0])\n",
    "mov = pims.open(ficheiros[1])\n",
    "# len(a)\n",
    "\n",
    "\n",
    "\n",
    "sizes = np.array([mov.frame_shape,ref.frame_shape]).T\n",
    "empty = sizes[0].max(),sizes[1].max()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_dapi = np.roll(mov[3],-2305,axis=1)\n",
    "mov_dapi = np.roll(mov_dapi,100,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapich = 3\n",
    "ref2 = np.zeros(empty)\n",
    "mov2 = np.zeros(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref2[:ref.frame_shape[0],:ref.frame_shape[1]] = ref[dapich]\n",
    "mov2[:mov.frame_shape[0],:mov.frame_shape[1]] = mov_dapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pims.Frame(ref2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ref\n",
    "del mov_dapi,mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Translational transformation\n",
    "sr = StackReg(StackReg.RIGID_BODY)\n",
    "mta1 = sr.register(\n",
    "    ref2[quarter[0]:-quarter[0],quarter[1]:-quarter[1]],\n",
    "    mov2[quarter[0]:-quarter[0],quarter[1]:-quarter[1]]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = tuple(np.round(np.array(ref2.shape)/5).astype('int'))\n",
    "#Translational transformation\n",
    "sr = StackReg(StackReg.AFFINE)\n",
    "mta1 = sr.register(\n",
    "    ref2[quarter[0]:-quarter[0],quarter[1]:-quarter[1]],\n",
    "    mov2[quarter[0]:-quarter[0],quarter[1]:-quarter[1]]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.98186010e-01, -9.85277006e-04,  1.08630602e+01],\n",
       "       [ 9.66418193e-04,  9.97938822e-01,  8.23410514e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta1 = np.array([\n",
    "       [ 9.99999951e-01, -3.12420350e-04,  3.28717291e+02],\n",
    "       [ 3.12420350e-04,  9.99999951e-01, -3.98938467e+01],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta1 = np.array([[ 1.00108756e+00,  1.24853472e-04, -1.21100576e+01],\n",
    "       [ 3.28726193e-03,  1.00099829e+00, -4.27326598e+01],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1 = sr.transform(mov2,tmat=mta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader will load image in-memory: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader will load image in-memory: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader will load image in-memory: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "v = napari.Viewer(ndisplay=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'test1' at 0x7f457da9a350>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.add_image(ref2,blending='additive',colormap='green')\n",
    "v.add_image(mov2,blending='additive',colormap='red')\n",
    "v.add_image(test1,blending='additive',colormap='cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e31c6e023dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test1' is not defined"
     ]
    }
   ],
   "source": [
    "mov\n",
    "mov2[:mov.frame_shape[0],:mov.frame_shape[1]] = mov[dapich]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficheiros = glob('/run/media/jmamede/Joao/multiplex/ENDO/out/*8bit*tiff')\n",
    "ficheiros.sort()\n",
    "\n",
    "#load reference and \"moved\" image\n",
    "ref = pims.open(ficheiros[0])\n",
    "mov = pims.open(ficheiros[1])\n",
    "\n",
    "\n",
    "sizes = np.array([mov.frame_shape,ref.frame_shape]).T\n",
    "empty = sizes[0].max(),sizes[1].max()\n",
    "\n",
    "ref2 = np.zeros(empty )\n",
    "mov2 = np.zeros(empty )\n",
    "\n",
    "\n",
    "sr = StackReg(StackReg.AFFINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quarter = tuple(np.round(np.array(ref2.shape)/5).astype('int'))\n",
    "\n",
    "\n",
    "# mta3 = sr.register(\n",
    "#     ref2[quarter[0]:-quarter[0],quarter[1]:-quarter[1]],\n",
    "#     mov2[quarter[0]:-quarter[0],quarter[1]:-quarter[1]]\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mta3 = np.array([[ 1.00108756e+00,  1.24853472e-04, -1.21100576e+01],\n",
    "#        [ 3.28726193e-03,  1.00099829e+00, -4.27326598e+01],\n",
    "#        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])\n",
    "\n",
    "mta3 = np.array([[ 9.98186010e-01, -9.85277006e-04,  1.08630602e+01],\n",
    "       [ 9.66418193e-04,  9.97938822e-01,  8.23410514e+00],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19813, 35570)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov2.reshape((1,1,)+(mov2.shape)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "prjfile = '/run/media/jmamede/Joao/multiplex/ENDO/out/img2_registered.tiff'\n",
    "\n",
    "\n",
    "# tifprj = tf.TiffWriter(prjfile, bigtiff=True, imagej=False)\n",
    "\n",
    "\n",
    "with tifffile.TiffWriter(prjfile, bigtiff=True, imagej=False) as tif:\n",
    "    for i in range(len(mov)):\n",
    "        print(i)\n",
    "        mov2 = np.zeros(empty).astype(np.uint8)\n",
    "        moving_rolling = np.roll(mov[i],-2305,axis=1)\n",
    "        moving_rolling = np.roll(moving_rolling,100,axis=0)\n",
    "\n",
    "        mov2[:mov.frame_shape[0],:mov.frame_shape[1]] = moving_rolling.astype(np.uint8)\n",
    "        del moving_rolling\n",
    "        test1 = sr.transform(mov2,tmat=mta3)\n",
    "        tif.save( test1.astype(np.uint8),\n",
    "            tile = (2048, 2048),\n",
    "#                         compression=9,\n",
    "#                         description = xml.to_xml(),\n",
    "            photometric='minisblack',\n",
    "            #, datetime= True\n",
    "            metadata= None,\n",
    "            contiguous=False,\n",
    "            )\n",
    "        del test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref2 = rebin(ref2,(ref2.shape[0]//2,ref2.shape[1]//2))\n",
    "mov2 = rebin(mov2,(mov2.shape[0]//2,mov2.shape[1]//2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17785, 9907)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n",
      "asdf\n",
      "63.4 µs ± 25.2 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r 2 print('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Translational transformation\n",
    "sr = StackReg(StackReg.TRANSLATION)\n",
    "out_tra = sr.register(ref2, mov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr2 = StackReg(StackReg.TRANSLATION)\n",
    "out_tra2 = sr2.register(ref[0][4940:14818,8893:26678], mov[0][4940:14818,8893:26678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tra = np.array([[  1.        ,   0.        , 641.24722516],\n",
    "       [  0.        ,   1.        , -83.64280372],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tra2 = np.array([[  1.        ,   0.        , 641.24722516*2],\n",
    "       [  0.        ,   1.        , -83.64280372*2],\n",
    "       [  0.        ,   0.        ,   1.        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref2 = np.zeros((19814,35570))\n",
    "mov2 = np.zeros((19814,35570))\n",
    "ref2[:ref.frame_shape[0],:ref.frame_shape[1]] = ref[0]\n",
    "mov2[:mov.frame_shape[0],:mov.frame_shape[1]] = mov[0]\n",
    "\n",
    "sr = StackReg(StackReg.TRANSLATION)\n",
    "test1 = sr.transform(mov2,tmat=out_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = StackReg(StackReg.TRANSLATION)\n",
    "test2 = s2.transform(mov[0],tmat=out_tra2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rigid Body transformation\n",
    "sr = StackReg(StackReg.RIGID_BODY)\n",
    "out_rot = sr.register(ref2, mov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rot = out_rot*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rot[2][2] = 1.0\n",
    "out_rot\n",
    "test2 = sr.transform(mov2,tmat=out_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.99999983e+00, -8.24006515e-04,  1.28852116e+03],\n",
       "       [ 8.24006515e-04,  1.99999983e+00, -1.70715351e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_rot[2][2] = 1\n",
    "out_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled Rotation transformation\n",
    "sr = StackReg(StackReg.SCALED_ROTATION)\n",
    "out_sca = sr.register(ref2, mov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affine transformation\n",
    "sr = StackReg(StackReg.AFFINE)\n",
    "out_aff = sr.register(ref2, mov2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.27281430e-01,  1.13811964e+00, -2.77346128e+03])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_aff[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilinear transformation\n",
    "sr = StackReg(StackReg.BILINEAR)\n",
    "out_bil = sr.register(ref2, mov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19814, 35570)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (19759,35570) into shape (19814,35570)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dea6f04bcd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreg_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmov2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreg_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreg_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;31m# reg_im[...,3] = out_rot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# reg_im[...,4] = out_sca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# reg_im[...,5] = out_aff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (19759,35570) into shape (19814,35570)"
     ]
    }
   ],
   "source": [
    "# reg_im = np.zeros((19814, 35570,4))\n",
    "# reg_im[...,0] = ref2\n",
    "# reg_im[...,1] = mov2\n",
    "# reg_im[...,2] = test1\n",
    "# reg_im[...,3] = test2\n",
    "\n",
    "# reg_im[...,3] = out_rot \n",
    "# reg_im[...,4] = out_sca\n",
    "# reg_im[...,5] = out_aff\n",
    "# reg_im[...,6] = out_tra\n",
    "# reg_im[...,7] = out_bil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19759, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19759, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19759, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19759, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19813, 33534) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cmap = ['green','red','cyan','red','red','red','red','red','red','red']\n",
    "\n",
    "for i,img in enumerate([ref[0],mov[0],test1,test2]):\n",
    "    v.add_image(img,name='image'+str(i),blending='additive',colormap=cmap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'image1 [1]' at 0x7f8d843c15d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n",
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/napari/_vispy/vispy_image_layer.py:186: UserWarning: data shape (19814, 35570) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  ndisplay=self.layer._ndisplay,\n"
     ]
    }
   ],
   "source": [
    "v.add_image(reg_im[...,2],name='image'+str(i),blending='additive',colormap=cmap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmamede/anaconda3/lib/python3.7/site-packages/pims/api.py:207: UserWarning: <class 'pims.tiff_stack.TiffStack_tifffile'> errored: 'NoneType' object has no attribute 'TiffFile'\n",
      "  warn(message)\n"
     ]
    }
   ],
   "source": [
    "import pims\n",
    "# from nd2reader import ND2Reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/home/jmamede/scripts')\n",
    "# from support_pla import othercolor, cell_mask, multiply, rebin\n",
    "from support_pla import convert16to8bits\n",
    "from pystackreg import StackReg\n",
    "\n",
    "# from skimage import io\n",
    "\n",
    "#load reference and \"moved\" image\n",
    "\n",
    "reg_channel = 3\n",
    "\n",
    "image0 = pims.open('/home/jmamede/Data/multiplex/KOTHP1/DAPI-iGFP-INmruby3-bactin647_v01_PRJ.Custom.ome.tiff')\n",
    "image1 = pims.open('/home/jmamede/Data/multiplex/KOTHP1/DAPI-1a11_488-241_647_v01_PRJ.Custom.ome.tiff')\n",
    "\n",
    "ref = image0[reg_channel]\n",
    "mov = image1[reg_channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reg(ref,mov,name):\n",
    "    from pystackreg import StackReg\n",
    "    transformations = {\n",
    "        'TRANSLATION': StackReg.TRANSLATION,\n",
    "        'RIGID_BODY': StackReg.RIGID_BODY,\n",
    "        'SCALED_ROTATION': StackReg.SCALED_ROTATION,\n",
    "        'AFFINE': StackReg.AFFINE,\n",
    "        'BILINEAR': StackReg.BILINEAR\n",
    "    }\n",
    "    sr = StackReg(transformations[name])\n",
    "    return sr.register(ref, mov,)\n",
    "\n",
    "def registration(image,tmat,name='AFFINE'):\n",
    "    from pystackreg import StackReg\n",
    "    from skimage import transform, io, exposure\n",
    "    transformations = {\n",
    "        'TRANSLATION': StackReg.TRANSLATION,\n",
    "        'RIGID_BODY': StackReg.RIGID_BODY,\n",
    "        'SCALED_ROTATION': StackReg.SCALED_ROTATION,\n",
    "        'AFFINE': StackReg.AFFINE,\n",
    "        'BILINEAR': StackReg.BILINEAR\n",
    "    }\n",
    "\n",
    "    sr = StackReg(transformations[name])\n",
    "    return sr.transform(image,tmat)\n",
    "    \n",
    "# def registration_gpu(image,tmat):\n",
    "#     #it's not working it's inverted....\n",
    "#     import cupy as cp\n",
    "#     from cupyx.scipy.ndimage import affine_transform\n",
    "    \n",
    "#     return cp.asnumpy(\n",
    "#         affine_transform(\n",
    "#             cp.asarray(image),\n",
    "#             cp.asarray(tmat)\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "matrix = calculate_reg(ref,mov,'AFFINE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1.sizes\n",
    "result = np.zeros((image1.sizes['t'],image1.sizes['x'],image1.sizes['y']))\n",
    "\n",
    "for i in range(image1.sizes['t']):\n",
    "    result[i,:,:] = registration(image1[i],matrix,'AFFINE')\n",
    "# result_gpu = registration_gpu(mov,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from vispy.color import Colormap\n",
    "v = napari.Viewer(ndisplay=2)\n",
    "# cmap = Colormap([[1, 0, 0], [0, 0, 0], [0, 0, 1]])\n",
    "# cmap = ['green','red','red','bluered','red','red','red','red','red','red']\n",
    "cmap = ['magenta','red','green','blue']\n",
    "\n",
    "names = ['B-actin','IN-mruby3','iGFP','DAPI','CA-241','Blank','PQBP1','DAPI2']\n",
    "j = 0\n",
    "for img in [image0,result]:\n",
    "    for i in range(4):\n",
    "        v.add_image(img[i],name=names[j],blending='additive',\n",
    "                    colormap=cmap[i]                    \n",
    "#                     colormap=('diverging', cmap)\n",
    "                   )\n",
    "        j +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
