{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycudadecon import decon\n",
    "import pycudadecon\n",
    "import pims\n",
    "import dask\n",
    "import dask.array as da\n",
    "import tifffile as tf\n",
    "from nd2reader import ND2Reader\n",
    "# from pims import ND2_Reader as ND2Reader\n",
    "# import aicsimageio.vendor.omexml as ome\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = ['miRFP670', 'mRuby3','FITC']\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "# for lens    \n",
    "#     reader.parser._raw_metadata.image_calibration\n",
    "\n",
    "# import re\n",
    "\n",
    "\n",
    "def Nd2meta2OMEXML(reader, project=False):\n",
    "#     from apeer_ometiff_library import omexmlClass\n",
    "    import aicsimageio.vendor.omexml as omexmlClass\n",
    "    import re\n",
    "    \n",
    "    #Missing TODO:\n",
    "    #<Image>,  Name = \"ImageName\"\n",
    "    #Instrument ID and Detector ID and Objective \n",
    "#     frames.parser._raw_metadata.image_metadata[b'SLxExperiment'][b'wsCameraName']\n",
    "\n",
    "    # Objective settings with Refractive Index\n",
    "        #Pixels, \n",
    "            #Channel Color = RGB###, EmissionWavelength, Name of Channel.\n",
    "            #Plane  ExposureTime, Position X, Y, Z (Z is easy as it's in nd2reader metadata)\n",
    "    def writeplanes(pixel, SizeT=1, SizeZ=1, SizeC=1, order='TZCYX', verbose=False):\n",
    "\n",
    "        if order == 'TZCYX':\n",
    "\n",
    "            pixel.DimensionOrder = omexmlClass.DO_XYCZT\n",
    "            counter = 0\n",
    "            for t in range(SizeT):\n",
    "                for z in range(SizeZ):\n",
    "                    for c in range(SizeC):\n",
    "\n",
    "                        if verbose:\n",
    "                            print('Write PlaneTable: ', t, z, c),\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                        pixel.Plane(counter).TheT = t\n",
    "                        pixel.Plane(counter).TheZ = z\n",
    "                        pixel.Plane(counter).TheC = c\n",
    "                        #check basically because of triggered acquisition the arrays shouldn't have the size of \"channel\"\n",
    "                        pixel.Plane(counter).DeltaT = reader.get_timesteps()[counter//SizeC]\n",
    "                        pixel.Plane(counter).PositionZ = nd2meta['z_coordinates'][counter//SizeC]\n",
    "#                         pixel.Plane(counter).ExposureTime = \n",
    "#                         pixel.Plane(counter).PositionX =\n",
    "#                         pixel.Plane(counter).PositionY = \n",
    "#                         pixel.Plane(counter).\n",
    "                        counter = counter + 1\n",
    "                        \n",
    "    \n",
    "        return pixel\n",
    "    \n",
    "    #make a metadata var\n",
    "    nd2meta = reader.metadata\n",
    "\n",
    "    extra_meta = reader.parser._raw_metadata.image_text_info[b'SLxImageTextInfo'][b'TextInfoItem_5'].decode()\n",
    "    extra_meta = re.split(',|;|\\r\\n',extra_meta)\n",
    "    extra_dict = dict()\n",
    "    for line in extra_meta: \n",
    "        line = line.strip().strip('- ')\n",
    "        keyvalue = str.split(line,':') \n",
    "        if len(keyvalue) > 1: \n",
    "            key = keyvalue[0] \n",
    "            value = keyvalue[1] \n",
    "            extra_dict[key] = value\n",
    "#     Series = nd2meta['fields_of_view'][-1]+1\n",
    "    scalex = nd2meta['pixel_microns']\n",
    "    scaley = scalex\n",
    "    \n",
    "    \n",
    "    \n",
    "    if not project:\n",
    "#         scalez = round(nd2meta['z_coordinates'][1]-nd2meta['z_coordinates'][0],3)\n",
    "#         scalez = frames.parser._raw_metadata.image_metadata[b'SLxExperiment'][b'ppNextLevelEx'][b''][b'ppNextLevelEx'][b''][b'uLoopPars'][b'dZStep']\n",
    "        scalez = extra_dict['Step'].split()[0]\n",
    "    pixeltype = 'uint16'\n",
    "    dimorder = 'TZCYX'\n",
    "# print(a)\n",
    "    omexml = omexmlClass.OMEXML()\n",
    "#     omexml.image_count = 1\n",
    "#     omexml.image_count = reader.sizes['v']\n",
    "    #Try to find if PIMS outputs the filename somehow.\n",
    "    omexml.image(0).Name = reader.filename\n",
    "#     for i in range(frames.sizes['t']):\n",
    "    p = omexml.image(0).Pixels\n",
    "    p.SizeX = frames.sizes['x']\n",
    "#     p.SizeX = 2044\n",
    "    p.SizeY = frames.sizes['y']\n",
    "    p.SizeC = frames.sizes['c']\n",
    "    p.SizeT = frames.sizes['t']\n",
    "    if project:\n",
    "        p.SizeZ = 1\n",
    "    else:\n",
    "        p.SizeZ = frames.sizes['z']\n",
    "        \n",
    "    p.PhysicalSizeX = np.float(scalex)\n",
    "    p.PhysicalSizeY = np.float(scaley)\n",
    "    if not project:\n",
    "        p.PhysicalSizeZ = np.float(scalez)\n",
    "    p.PixelType = pixeltype\n",
    "    p.channel_count = frames.sizes['c']\n",
    "    \n",
    "    if project:\n",
    "        p.plane_count = 1 * p.SizeT * p.SizeC #* SizeV\n",
    "    else:\n",
    "        p.plane_count = p.SizeZ * p.SizeT * p.SizeC #* SizeV\n",
    "\n",
    "\n",
    "    #I am using separate files for each visit point\n",
    "    #, if you want one tiff with all visit points (possibly good for panels) \n",
    "    #you will need to update this section\n",
    "    \n",
    "    if project:\n",
    "        p = writeplanes(p, SizeT=p.SizeT, SizeZ=1, SizeC=p.SizeC, order=dimorder)\n",
    "    else:\n",
    "        p = writeplanes(p, SizeT=p.SizeT, SizeZ=p.SizeZ, SizeC=p.SizeC, order=dimorder)\n",
    "    for c in range(p.SizeC):\n",
    "        p.Channel(c).Name = nd2meta['channels'][c]\n",
    "        clr = {'miRFP670':  65535 ,'mRuby3' : -16776961,'mRuby' : -16776961, 'a647': 65535,'GFP': 16711935,'FITC': 16711935,'DAPI': 65535}\n",
    "        p.Channel(c).Color = clr[p.Channel(c).Name]\n",
    "#         p.Channel(c).EmissionWavelength =\n",
    "        if pixeltype == 'unit8':\n",
    "            p.Channel(c).SamplesPerPixel = 1\n",
    "        if pixeltype == 'unit16':\n",
    "            p.Channel(c).SamplesPerPixel = 1\n",
    "            \n",
    "    p.populate_TiffData()\n",
    "#     omexml.structured_annotations.add_original_metadata(omexmlClass.OM_SAMPLES_PER_PIXEL, str(p.SizeC))\n",
    "\n",
    "    return omexml\n",
    "\n",
    "def observer(img, i, *args):\n",
    "    #mgs.append(img.max(axis=0))\n",
    "    if i % 5 == 0:\n",
    "        print('Observing iteration = {} (dtype = {}, max = {:.3f})'.format(i, img.dtype, img.max()))   \n",
    "#config = tf.ConfigProto(device_count={'GPU': 1})\n",
    "#algo = fd_restoration.RichardsonLucyDeconvolver(n_dims=acq.data.ndim, pad_min=[1, 1, 1], session_config=config).initialize()\n",
    "\n",
    "# def init_RL_algo(imshape,otf,dZ):\n",
    "#     from pycudadecon import RLContext, rl_init, TemporaryOTF\n",
    "# #     with TemporaryOTF(psf) as otf:\n",
    "#     ctx = RLContext(imshape, otf, dzpsf=dZ, dzdata=dZ, dxdata='0.108',dxpsf='0.108')\n",
    "#     return ctx\n",
    "# #     return ctx.out_shap\n",
    "\n",
    "# #\n",
    "\n",
    "def deconv(chunk, otf, xmldata, iters=20):\n",
    "    import pycudadecon\n",
    "    from pycudadecon import decon\n",
    "#     psf, algo,\n",
    "    arguments = {\n",
    "    'dxdata' : xmldata.image(0).Pixels.PhysicalSizeX,\n",
    "    'dzdata' : xmldata.image(0).Pixels.PhysicalSizeZ,\n",
    "    'dxpsf': xmldata.image(0).Pixels.PhysicalSizeX,\n",
    "    'dzpsf' : 0.3,\n",
    "    'n_iters' :iters,\n",
    "    'wavelength' :520,\n",
    "    'na':1.4,\n",
    "    'nimm': 1.3,\n",
    "#     'output_shape':ctx.out_shape\n",
    "                }\n",
    "    return decon(chunk, otf ,arguments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # algo =init_RL_algo(imshape,otf,scalez)\n",
    "# from pycudadecon import decon\n",
    "# result = decon(frames[0],'/home/jmamede/Rush/PSF/mRuby3_0.3_otf.tif',arguments)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/run/media/jmamede/Joao/till/Till/B01.nd2']\n",
      "(2044, 2048)\n",
      "['mRuby', 'GFP', 'DAPI']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fname = 'igfp1_caruby5_continue001trigger003.nd2'\n",
    "# dirname = \"Y:/IMMUN/Mamede/20200630/*.nd2\"\n",
    "#THINGS TO CHANGE!!!!! Always keep /*.nd2 at the end\n",
    "\n",
    "#dirname = \"X:/Mamede/Stephanie/20200902/*.nd2\"\n",
    "dirname = \"/run/media/jmamede/Joao/till/Till/B01.nd2\"\n",
    "filelist = glob.glob(dirname)\n",
    "filelist.sort()\n",
    "print(filelist)\n",
    "\n",
    "ydivide = 2\n",
    "xdivide = 2\n",
    "\n",
    "frames = ND2Reader(filelist[0])\n",
    "frames.iter_axes = 't'  # 't' is the default already\n",
    "frames.bundle_axes = 'zyx'  # when 'z' is available, this will be default\n",
    "chunk_size=(frames.sizes['z'],frames.sizes['y']//ydivide,frames.sizes['x']//xdivide)\n",
    "frames.default_coords['v'] = 0\n",
    "print((frames.sizes['y'],frames.sizes['x']))\n",
    "\n",
    "metadata = frames.metadata\n",
    "print(metadata['channels'])\n",
    "\n",
    "\n",
    "\n",
    "if xdivide >1 and ydivide >1:\n",
    "    depthdivide = (0,62,64)\n",
    "elif xdivide > 1 and ydivide == 1:\n",
    "        depthdivide = (0,0,64)\n",
    "else:\n",
    "        depthdivide = (0,0,0)\n",
    "# print(frames.parser._raw_metadata.image_metadata[b'SLxExperiment'][b'ppNextLevelEx'][b''][b'ppNextLevelEx'][b''][b'uLoopPars'][b'dZStep'])\n",
    "\n",
    "metadata['pixel_microns']\n",
    "xml = Nd2meta2OMEXML(frames)\n",
    "xml.image(0).Pixels.PhysicalSizeZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 256, 256)\n",
      "(129, 70)\n"
     ]
    }
   ],
   "source": [
    "psf647 = tf.imread(\"/home/jmamede/Rush/PSF/AF647_0.3.tif\")\n",
    "psfruby =  tf.imread('/home/jmamede/Rush/PSF/mRuby3_0.3_otf.tif')\n",
    "psfgfp =  tf.imread('/home/jmamede/Rush/PSF/green_0.3.tif')\n",
    "psfdapi =  tf.imread('/home/jmamede/Rush/PSF/DAPI_0.3.tif')\n",
    "print(psf647.shape)\n",
    "print(psfruby.shape)\n",
    "\n",
    "otf_path = '/home/jmamede/Rush/PSF/mRuby3_0.3_otf.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf647 = psf647[5:-5,64:-63,64:-63]\n",
    "# # psfruby = psfruby[1:-1]\n",
    "# psfgfp = psfgfp[1:-1]\n",
    "# psfdapi = psfdapi[1:-1]\n",
    "# print(psf647.shape)\n",
    "# print(psfruby.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 2\n",
    "# session = InteractiveSession(config=config)\n",
    "# prjxml = Nd2meta2OMEXML(frames, project=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in filelist:\n",
    "    frames =  ND2Reader(fname)\n",
    "    frames.iter_axes = 't'  # 't' is the default already\n",
    "    frames.bundle_axes = 'zyx'  # when 'z' is available, this will be default\n",
    "    # frames.iter_axes\n",
    "    channels =  frames.metadata['channels']\n",
    "    metadata = frames.metadata\n",
    "    xml = Nd2meta2OMEXML(frames)\n",
    "    prjxml = Nd2meta2OMEXML(frames, project=True)\n",
    "\n",
    "    psf =[]\n",
    "    #psf = fd_psf.GibsonLanni.load('/tmp/psf.json')\n",
    "\n",
    "    # args = [na=1.4, wavelength= 0.594 , size_z=  11, size_x=  2048, size_y=  2044,\n",
    "    #         m :60,ns =  1.333, ni =  1.5156, tg =  170,         \n",
    "    #         res_lateral =  0.108333333333333, res_axial =  0.3, pZ = 1]\n",
    "\n",
    "    # args = [{\"na\": 1.4, \"wavelength\": '0.594' ,\n",
    "    #          \"size_z\": 11, \"size_x\": 2048, \"size_y\": 2044,\n",
    "    #          \"m\" :60,\"ns\" : 1.333, \"ni\" : 1.5156, \"tg\" : 170,\n",
    "    #          \"res_lateral\" : 0.108333333333333, \"res_axial\" : 0.3,\n",
    "    #          \"pZ\" :1}]\n",
    "\n",
    "    #na = meta['NA']\n",
    "\n",
    " \n",
    "    chunk_size=(frames.sizes['z'],frames.sizes['y']//ydivide,frames.sizes['x']//xdivide)\n",
    "\n",
    "\n",
    "    # frames.iter_axes = 'v'\n",
    "    # for frame in frames:\n",
    "    for visit in range(frames.sizes['v']):\n",
    "#     for visit in range(21,31):\n",
    "        #%timeit\n",
    "        frames.default_coords['v'] = visit\n",
    "        stackfile = fname[:-4]+\"_v\"+str(visit+1)+'_pycuda.ome.tiff'\n",
    "        prjfile = fname[:-4]+\"_v\"+str(visit+1)+'_PRJ_pycuda.ome.tiff'\n",
    "        \n",
    "        with tf.TiffWriter(stackfile, bigtiff=True , imagej=False) as tif,tf.TiffWriter(prjfile, bigtiff=True, imagej=False) as tifprj:\n",
    "            first = True\n",
    "#             print('Visit:',visit)\n",
    "            for time in range(frames.sizes['t']):\n",
    "#                 print('Time:',time)\n",
    "                res = np.zeros(\n",
    "                    (frames.sizes['z'],frames.sizes['c']\n",
    "                     ,frames.sizes['y'],frames.sizes['x'])\n",
    "#                      ,2044,2044)\n",
    "                    , dtype=np.float32)\n",
    "                for i in range(frames.sizes['c']):\n",
    "                    frames.default_coords['c'] = i\n",
    "#                     print('Channel:',metadata['channels'][i])\n",
    "                    ch = metadata['channels'][i]\n",
    "    #     ['a647', 'DAPI', 'GFP']\n",
    "    # ['FITC', 'mRuby3', 'miRFP670']\n",
    "#         ['FRET-gYFP-dsRED', 'mRuby', 'GFP', 'DAPI']\n",
    "# ['a647', 'DAPI', 'GFP']\n",
    "                    if ch == 'DAPI' or ch  == '470 nm':\n",
    "                        psf = psfdapi\n",
    "                    elif ch == 'miRFP670' or ch == 'a647':\n",
    "                        psf = psf647\n",
    "                    elif ch == 'GFP' or ch == 'FITC':\n",
    "                        psf = psfgfp\n",
    "                    elif ch == 'mRuby3' or ch == 'mRuby' or ch ==  '555 nm':\n",
    "                        psf = psfruby\n",
    "                    elif ch == 'FRET-gYFP-dsRED':\n",
    "                        psf = psfruby\n",
    "#                     print(frames[time].shape)\n",
    "                    arr = da.from_array(frames[time]\n",
    "#                                         [:,0:2044,0:2044]\n",
    "    #                                     [:,:,:]              \n",
    "                                        , chunks=chunk_size)\n",
    "#                     print(frames[time].shape,i, frames[i].max())\n",
    "\n",
    "                    res[:,i,:,:] = da.map_overlap(deconv, arr , depth  = depthdivide ,boundary='reflect'\n",
    "                            ,dtype='float32', otf=otf_path, xmldata=xml, iters=20).compute(num_workers=1)\n",
    "        #                     res[i,:,:,:] = arr.map_blocks(\n",
    "        #                         deconv,dtype='float32').compute(num_workers=1)\n",
    "\n",
    "#                     res = da.overlap.trim_internal(res, {0, 16:-16, 16: -16})\n",
    "    # If we need to swap Channel and Z in the future\n",
    "    #             img5d = np.swapaxes(img5d,0,1)\n",
    "\n",
    "                    update_progress( (visit+1) * (time+1) / (frames.sizes['v']* frames.sizes['t']) )\n",
    "                    print(\"Visit Point: {}/{} \\t Time:{}/{} \\t Channel:{}/{}\".format(\n",
    "                            visit+1, frames.sizes['v']\n",
    "                            ,time+1, frames.sizes['t']\n",
    "                            , i+1, frames.sizes['c']))\n",
    "\n",
    "                if first:\n",
    "                    tif.save(res.astype(np.uint16)\n",
    "#                             , compress='LZMA'\n",
    "                        , description = xml.to_xml()\n",
    "                        , photometric='minisblack'\n",
    "                        #, datetime= True\n",
    "                        , metadata= None\n",
    "                        , contiguous=False\n",
    "                        )\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0)\n",
    "#                             , compress='LZMA'\n",
    "                        , description = prjxml.to_xml()\n",
    "                        , photometric='minisblack'\n",
    "                        #, datetime= True\n",
    "                        , metadata= None\n",
    "                        , contiguous=False\n",
    "                        )\n",
    "                    first = False\n",
    "                else:\n",
    "                    tif.save(res.astype(np.uint16)\n",
    "#                             , compress='LZMA'\n",
    "#                         , description = xml.to_xml()\n",
    "                        , photometric='minisblack'\n",
    "                        , metadata= None\n",
    "                        , contiguous=False\n",
    "                        )\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0)\n",
    "#                             , compress='LZMA'\n",
    "#                         , description = xml.to_xml()\n",
    "                        , photometric='minisblack'\n",
    "                        #, datetime= True\n",
    "                        , metadata= None\n",
    "                        , contiguous=False\n",
    "                        )\n",
    "\n",
    "        tif.close()\n",
    "        tifprj.close()\n",
    "\n",
    "    update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
