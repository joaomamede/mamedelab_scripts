{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flowdec.nb import utils as nbutils \n",
    "from flowdec import data as fd_data\n",
    "import pims\n",
    "# import pims\n",
    "from flowdec import restoration as fd_restoration\n",
    "from flowdec import data as fd_data\n",
    "from flowdec import psf as fd_psf\n",
    "import dask\n",
    "import dask.array as da\n",
    "import tifffile as tf\n",
    "from nd2reader import ND2Reader\n",
    "# from pims import ND2_Reader as ND2Reader\n",
    "# import aicsimageio.vendor.omexml as ome\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = ['miRFP670', 'mRuby3','FITC']\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "def Nd2meta2OMEXML(reader, project=False):\n",
    "#     from apeer_ometiff_library import omexmlClass\n",
    "    import aicsimageio.vendor.omexml as omexmlClass\n",
    "    \n",
    "    #Missing TODO:\n",
    "    #<Image>,  Name = \"ImageName\"\n",
    "    #Instrument ID and Detector ID and Objective \n",
    "#     frames.parser._raw_metadata.image_metadata[b'SLxExperiment'][b'wsCameraName']\n",
    "\n",
    "    # Objective settings with Refractive Index\n",
    "        #Pixels, \n",
    "            #Channel Color = RGB###, EmissionWavelength, Name of Channel.\n",
    "            #Plane  ExposureTime, Position X, Y, Z (Z is easy as it's in nd2reader metadata)\n",
    "    def writeplanes(pixel, SizeT=1, SizeZ=1, SizeC=1, order='TZCYX', verbose=False):\n",
    "\n",
    "        if order == 'TZCYX':\n",
    "\n",
    "            pixel.DimensionOrder = omexmlClass.DO_XYCZT\n",
    "            counter = 0\n",
    "            for t in range(SizeT):\n",
    "                for z in range(SizeZ):\n",
    "                    for c in range(SizeC):\n",
    "\n",
    "                        if verbose:\n",
    "                            print('Write PlaneTable: ', t, z, c),\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                        pixel.Plane(counter).TheT = t\n",
    "                        pixel.Plane(counter).TheZ = z\n",
    "                        pixel.Plane(counter).TheC = c\n",
    "                        #check basically because of triggered acquisition the arrays shouldn't have the size of \"channel\"\n",
    "                        pixel.Plane(counter).DeltaT = reader.get_timesteps()[counter//SizeC]\n",
    "                        pixel.Plane(counter).PositionZ = nd2meta['z_coordinates'][counter//SizeC]\n",
    "#                         pixel.Plane(counter).ExposureTime = \n",
    "#                         pixel.Plane(counter).PositionX =\n",
    "#                         pixel.Plane(counter).PositionY = \n",
    "#                         pixel.Plane(counter).\n",
    "                        counter = counter + 1\n",
    "                        \n",
    "    \n",
    "        return pixel\n",
    "    \n",
    "    #make a metadata var\n",
    "    nd2meta = reader.metadata\n",
    "    extra_meta = reader.parser._raw_metadata.image_text_info[b'SLxImageTextInfo'][b'TextInfoItem_5'].decode()\n",
    "    extra_meta = re.split(',|;|\\r\\n',extra_meta)\n",
    "    extra_dict = dict()\n",
    "    for line in extra_meta: \n",
    "        line = line.strip().strip('- ')\n",
    "        keyvalue = str.split(line,':') \n",
    "        if len(keyvalue) > 1: \n",
    "            key = keyvalue[0] \n",
    "            value = keyvalue[1] \n",
    "            extra_dict[key] = value\n",
    "#     Series = nd2meta['fields_of_view'][-1]+1\n",
    "#     Series = nd2meta['fields_of_view'][-1]+1\n",
    "    scalex = nd2meta['pixel_microns']\n",
    "    scaley = scalex\n",
    "    \n",
    "    if not project:\n",
    "#         scalez = round(nd2meta['z_coordinates'][1]-nd2meta['z_coordinates'][0],3)\n",
    "#         scalez = frames.parser._raw_metadata.image_metadata[b'SLxExperiment'][b'ppNextLevelEx'][b''][b'ppNextLevelEx'][b''][b'uLoopPars'][b'dZStep']\n",
    "        scalez = extra_dict['Step'].split()[0]\n",
    "    pixeltype = 'uint16'\n",
    "    dimorder = 'TZCYX'\n",
    "    \n",
    "# print(a)\n",
    "    omexml = omexmlClass.OMEXML()\n",
    "#     omexml.image_count = 1\n",
    "#     omexml.image_count = reader.sizes['v']\n",
    "    #Try to find if PIMS outputs the filename somehow.\n",
    "    omexml.image(0).Name = reader.filename\n",
    "#     for i in range(frames.sizes['t']):\n",
    "    p = omexml.image(0).Pixels\n",
    "    p.SizeX = frames.sizes['x']\n",
    "#     p.SizeX = 2044\n",
    "    p.SizeY = frames.sizes['y']\n",
    "    p.SizeC = frames.sizes['c']\n",
    "    p.SizeT = frames.sizes['t']\n",
    "    if project:\n",
    "        p.SizeZ = 1\n",
    "    else:\n",
    "        p.SizeZ = frames.sizes['z']\n",
    "        \n",
    "    p.PhysicalSizeX = np.float(scalex)\n",
    "    p.PhysicalSizeY = np.float(scaley)\n",
    "    if not project:\n",
    "        p.PhysicalSizeZ = np.float(scalez)\n",
    "    p.PixelType = pixeltype\n",
    "    p.channel_count = frames.sizes['c']\n",
    "    \n",
    "    if project:\n",
    "        p.plane_count = 1 * p.SizeT * p.SizeC #* SizeV\n",
    "    else:\n",
    "        p.plane_count = p.SizeZ * p.SizeT * p.SizeC #* SizeV\n",
    "\n",
    "\n",
    "    #I am using separate files for each visit point\n",
    "    #, if you want one tiff with all visit points (possibly good for panels) \n",
    "    #you will need to update this section\n",
    "    \n",
    "    if project:\n",
    "        p = writeplanes(p, SizeT=p.SizeT, SizeZ=1, SizeC=p.SizeC, order=dimorder)\n",
    "    else:\n",
    "        p = writeplanes(p, SizeT=p.SizeT, SizeZ=p.SizeZ, SizeC=p.SizeC, order=dimorder)\n",
    "    for c in range(p.SizeC):\n",
    "        p.Channel(c).Name = nd2meta['channels'][c]\n",
    "        clr = {'miRFP670':  65535 ,'mRuby3' : -16776961,'mRuby' : -16776961, 'a647': 65535,'GFP': 16711935,'FITC': 16711935,'DAPI': 65535}\n",
    "        p.Channel(c).Color = clr[p.Channel(c).Name]\n",
    "#         p.Channel(c).Color =\n",
    "#         p.Channel(c).EmissionWavelength =\n",
    "        if pixeltype == 'unit8':\n",
    "            p.Channel(c).SamplesPerPixel = 1\n",
    "        if pixeltype == 'unit16':\n",
    "            p.Channel(c).SamplesPerPixel = 1\n",
    "            \n",
    "    p.populate_TiffData()\n",
    "#     omexml.structured_annotations.add_original_metadata(omexmlClass.OM_SAMPLES_PER_PIXEL, str(p.SizeC))\n",
    "\n",
    "    return omexml\n",
    "\n",
    "def observer(img, i, *args):\n",
    "    #mgs.append(img.max(axis=0))\n",
    "#     if i % 5 == 0:\n",
    "    print('Observing iteration = {} (dtype = {}, max = {:.3f})'.format(i, img.dtype, img.max()))   \n",
    "#config = tf.ConfigProto(device_count={'GPU': 1})\n",
    "#algo = fd_restoration.RichardsonLucyDeconvolver(n_dims=acq.data.ndim, pad_min=[1, 1, 1], session_config=config).initialize()\n",
    "\n",
    "def init_RL_algo(psfdims,pad_mode='2357',pad_min=(0,1,1)):\n",
    "#psfgfp.ndim\n",
    "    algo = fd_restoration.RichardsonLucyDeconvolver(n_dims=psfdims\n",
    "                                                    , pad_mode=pad_mode\n",
    "    #                                                     , pad_mode='none'\n",
    "                                                    ,pad_min=pad_min\n",
    "    #                                                     ,observer_fn=observer\n",
    "                                                    #,real_domain_fft=True\n",
    "                                                    #,device='/cpu:0'\n",
    "                                                   ).initialize()\n",
    "    return algo\n",
    "\n",
    "def deconv(chunk, algo, psf ,iters=20):\n",
    "#     psf, algo,\n",
    "#     iters=20\n",
    "    # note that algo and cropped_kernel are from global scope ... ugly\n",
    "#     print(\"chunk shape\", chunk.shape)\n",
    "    tmp = algo.run(fd_data.Acquisition(data=chunk, kernel=psf)\n",
    "#                                 , session_config = tef.compat.v1.ConfigProto(device_count={'GPU': 0})\n",
    "#                                 , session_config=tflow.compat.v1.ConfigProto(\n",
    "#                                 device_count={'GPU': 1}        \n",
    "#                                 , GPUOptions={'allow_growth' : 4}\n",
    "#                                         )\n",
    "                                ,niter=iters\n",
    "                               )\n",
    "    return tmp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jmamede/Data/pqbp1/20200824pqbp1/B1.nd2']\n",
      "{'x': 2048, 'y': 2044, 'c': 4, 't': 1, 'z': 35, 'v': 10}\n",
      "['a647', 'GFP', 'mRuby', 'DAPI']\n",
      "(0, 62, 64)\n"
     ]
    }
   ],
   "source": [
    "# fname = 'igfp1_caruby5_continue001trigger003.nd2'\n",
    "# dirname = \"Y:/IMMUN/Mamede/20200630/*.nd2\"\n",
    "#THINGS TO CAHNGE!!!!! Always keep /*.nd2 at the end\n",
    "\n",
    "# Progress: [###-----------------] 14.5%\n",
    "# Visit Point: 21/31 \t Time:15/70 \t Channel:3/3\n",
    "# D:\\Stephanie\\20200828\n",
    "# dirname = \"/home/jmamede/Data/CaRuby3/20200910VOG/*.nd2\"\n",
    "dirname = \"/home/jmamede/Data/pqbp1/20200824pqbp1/B1.nd2\"\n",
    "filelist = glob.glob(dirname)\n",
    "filelist.sort()\n",
    "print(filelist)\n",
    "\n",
    "frames = ND2Reader(filelist[0])\n",
    "print(frames.sizes)\n",
    "\n",
    "metadata = frames.metadata\n",
    "print(metadata['channels'])\n",
    "\n",
    "ydivide = 2\n",
    "xdivide = 2\n",
    "\n",
    "if xdivide >1 and ydivide >1:\n",
    "    depthdivide = (0,62,64)\n",
    "elif xdivide > 1 and ydivide == 1:\n",
    "        depthdivide = (0,0,64)\n",
    "else:\n",
    "        depthdivide = (0,0,0)\n",
    "# print(frames.parser._raw_metadata.image_metadata[b'SLxExperiment'][b'ppNextLevelEx'][b''][b'ppNextLevelEx'][b''][b'uLoopPars'][b'dZStep'])\n",
    "print(depthdivide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 256, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# psf647 = tf.imread(\"/home/jmamede/Data/PSF/AF647_0.3.tif\")\n",
    "# psfruby =  tf.imread('/home/jmamede/Data/PSF/mRuby3_0.3.tif')\n",
    "\n",
    "# psfgfp =  tf.imread('/home/jmamede/Data/PSF/green_0.3.tif')\n",
    "# psfdapi =  tf.imread('/home/jmamede/Data/PSF/DAPI_0.3.tif')\n",
    "psf647 = tf.imread(\"/home/jmamede/Data/PSF/AF647.tif\")\n",
    "psfruby =  tf.imread('/home/jmamede/Data/PSF/mRuby3.tif')\n",
    "\n",
    "psfgfp =  tf.imread('/home/jmamede/Data/PSF/green.tif')\n",
    "psfdapi =  tf.imread('/home/jmamede/Data/PSF/DAPI.tif')\n",
    "psfgfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 128, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psf647 = psf647[:,64:-64,64:-64]\n",
    "psfruby = psfruby[:,64:-64,64:-64]\n",
    "psfgfp = psfgfp[:,64:-64,64:-64]\n",
    "psfdapi = psfdapi[:,64:-64,64:-64]\n",
    "psfgfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##------------------] 10.0%\n",
      "Visit Point: 1/10 \t Time:1/1 \t Channel:1/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1ea0ce679b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0;31m#  depthdivide = {0:0 , 1:62, 2:65}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     res[:,i,:,:] = da.map_overlap(deconv, arr , depth  = (0,0,64),boundary='reflect'\n\u001b[0;32m---> 81\u001b[0;31m                             ,dtype='float32', algo=algo, psf=psf, iters=20).compute(num_workers=1)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#                     res[i,:,:,:] = arr.map_blocks(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mpack_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"waiting\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"running\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 2\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "algo =init_RL_algo(psfgfp.ndim)\n",
    "\n",
    "for fname in filelist:\n",
    "    frames =  ND2Reader(fname)\n",
    "    frames.iter_axes = 't'  # 't' is the default already\n",
    "    frames.bundle_axes = 'zyx'  # when 'z' is available, this will be default\n",
    "    # frames.iter_axes\n",
    "    channels =  frames.metadata['channels']\n",
    "    metadata = frames.metadata\n",
    "    xml = Nd2meta2OMEXML(frames)\n",
    "    prjxml = Nd2meta2OMEXML(frames, project=True)\n",
    "\n",
    "    psf =[]\n",
    "\n",
    "    # chunk_size=(frames.sizes['z'],511,511)\n",
    "    chunk_size=(frames.sizes['z'],frames.sizes['y']//ydivide,frames.sizes['x']//xdivide)\n",
    "\n",
    "\n",
    "    # frames.iter_axes = 'v'\n",
    "    # for frame in frames:\n",
    "    for visit in range(frames.sizes['v']):\n",
    "#     for visit in range(3,10):\n",
    "        #%timeit\n",
    "        frames.default_coords['v'] = visit \n",
    "        stackfile = fname[:-4]+\"_v\"+str(visit+1)+'.ome.tiff'\n",
    "        prjfile = fname[:-4]+\"_v\"+str(visit+1)+'_PRJ.ome.tiff'\n",
    "        \n",
    "        with tf.TiffWriter(stackfile, bigtiff=True , imagej=False) as tif,tf.TiffWriter(prjfile, bigtiff=True, imagej=False) as tifprj:\n",
    "#             print('Visit:',visit)\n",
    "            first = True\n",
    "            for time in range(frames.sizes['t']):\n",
    "#                 print('Time:',time)\n",
    "                res = np.zeros(\n",
    "                    (frames.sizes['z'],frames.sizes['c']\n",
    "                     ,frames.sizes['y'],frames.sizes['x'])\n",
    "#                      ,2044,2044)\n",
    "                    , dtype=np.float32)\n",
    "                for i in range(frames.sizes['c']):\n",
    "                    frames.default_coords['c'] = i\n",
    "#                     print('Channel:',metadata['channels'][i])\n",
    "                    ch = metadata['channels'][i]\n",
    "    #     ['a647', 'DAPI', 'GFP']\n",
    "    # ['FITC', 'mRuby3', 'miRFP670']\n",
    "#         ['FRET-gYFP-dsRED', 'mRuby', 'GFP', 'DAPI']\n",
    "# ['a647', 'DAPI', 'GFP']\n",
    "                    if ch == 'DAPI' or ch  == '470 nm':\n",
    "                        psf = psfdapi\n",
    "                    elif ch == 'miRFP670' or ch == 'a647':\n",
    "                        psf = psf647\n",
    "                    elif ch == 'GFP' or ch == 'FITC':\n",
    "                        psf = psfgfp\n",
    "                    elif ch == 'mRuby3' or ch == 'mRuby' or ch ==  '555 nm':\n",
    "                        psf = psfruby\n",
    "                    elif ch == 'FRET-gYFP-dsRED':\n",
    "                        psf = psfruby\n",
    "#                     print(frames[time].shape)\n",
    "                    arr = da.from_array(frames[time]\n",
    "#                                         [:,0:2044,0:2044]\n",
    "    #                                     [:,:,:]              \n",
    "                                        , chunks=chunk_size)\n",
    "#                     print(frames[time].shape,i, frames[i].max())\n",
    "                        #  depthdivide = {0:0 , 1:62, 2:65}\n",
    "                    res[:,i,:,:] = da.map_overlap(deconv, arr , depth  = depthdivide ,boundary='reflect'\n",
    "                            ,dtype='float32', algo=algo, psf=psf, iters=20).compute(num_workers=1)\n",
    "        \n",
    "        #                     res[i,:,:,:] = arr.map_blocks(\n",
    "        #                         deconv,dtype='float32').compute(num_workers=1)\n",
    "\n",
    "    # If we need to swap Channel and Z in the future\n",
    "    #             img5d = np.swapaxes(img5d,0,1)\n",
    "\n",
    "                    update_progress( (visit+1) * (time+1) / (frames.sizes['v']* frames.sizes['t']) )\n",
    "                    print(\"Visit Point: {}/{} \\t Time:{}/{} \\t Channel:{}/{}\".format(\n",
    "                            visit+1, frames.sizes['v']\n",
    "                            ,time+1, frames.sizes['t']\n",
    "                            , i+1, frames.sizes['c']))\n",
    "\n",
    "                if first:\n",
    "#                         tif.save(res.astype(np.uint16)\n",
    "#                             , compress='LZMA'\n",
    "#                             , description = xml.to_xml()\n",
    "#                             , photometric='minisblack'\n",
    "#                             #, datetime= True\n",
    "#                             , metadata= None\n",
    "#                             , contiguous=False\n",
    "#                             )\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0)\n",
    "#                             , compress='LZMA'\n",
    "                        , description = prjxml.to_xml()\n",
    "                        , photometric='minisblack'\n",
    "                        #, datetime= True\n",
    "                        , metadata= None\n",
    "                        , contiguous=False\n",
    "                        )\n",
    "                    first = False\n",
    "                else:\n",
    "#                         tif.save(res.astype(np.uint16)\n",
    "#                             , compress='LZMA'\n",
    "#     #                         , description = xml.to_xml()\n",
    "#                             , photometric='minisblack'\n",
    "#                             , metadata= None\n",
    "#                             , contiguous=False\n",
    "#                             )\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0)\n",
    "#                             , compress='LZMA'\n",
    "#                         , description = xml.to_xml()\n",
    "                        , photometric='minisblack'\n",
    "                        #, datetime= True\n",
    "                        , metadata= None\n",
    "                        , contiguous=False\n",
    "                        )\n",
    "\n",
    "        tif.close()\n",
    "        tifprj.close()\n",
    "\n",
    "    update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
