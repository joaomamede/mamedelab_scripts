{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4OYbAcAhSqg",
    "outputId": "8ff1c3de-0461-4ca0-c109-7e15621935fd"
   },
   "outputs": [],
   "source": [
    "# !pip install dask>2.30.0\n",
    "# !pip install nd2reader\n",
    "# !pip install pims\n",
    "# !pip install flowdec\n",
    "# !pip install aicsimageio==3.3.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ea0EhwtehODd",
    "outputId": "d461f3d1-ea7d-4a00-8795-e673231fa9dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flowdec.nb import utils as nbutils \n",
    "from flowdec import data as fd_data\n",
    "# import pims\n",
    "# import pims\n",
    "from flowdec import restoration as fd_restoration\n",
    "from flowdec import data as fd_data\n",
    "from flowdec import psf as fd_psf\n",
    "import dask\n",
    "import dask.array as da\n",
    "import tifffile as tf\n",
    "from nd2reader import ND2Reader\n",
    "# from pims import ND2_Reader \n",
    "# import aicsimageio.vendor.omexml as ome\n",
    "import glob\n",
    "import time, sys\n",
    "sys.path.insert(0,'./libraries')\n",
    "sys.path.insert(0,'./')\n",
    "from deco_libraries import update_progress, pimsmeta2OMEXML, Nd2meta2OMEXML, observer, init_RL_algo, deconv, depth_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UETNBsoKhODh",
    "outputId": "bcbc78b8-16bb-473f-91c0-e0391ceca7e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./20210611_E1_cGas_1A11PQBC1_241D_7131.nd2']\n",
      "{'x': 1024, 'y': 1024, 'c': 4, 't': 1, 'z': 66, 'v': 10}\n",
      "['pqbp1-AF647', 'mRuby3', 'Igfp', 'Cgas-DY405']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<FramesSequenceND>\n",
       "Axes: 6\n",
       "Axis 'x' size: 1024\n",
       "Axis 'y' size: 1024\n",
       "Axis 'c' size: 4\n",
       "Axis 't' size: 1\n",
       "Axis 'z' size: 66\n",
       "Axis 'v' size: 10\n",
       "Pixel Datatype: <class 'numpy.float64'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THINGS TO CHANGE!!!!! Always keep /*.nd2 at the end\n",
    "#For gui make a function with all this input for verification purposes when loading the files\n",
    "# dirname = \"D:/igfp1_caruby5_continue001trigger002.nd2\"\n",
    "# dirname = \"D:/JM/20201222caru3/Carubyigfp_F2_Nh4cl_vitc_rutin_BVD002.nd2\"\n",
    "# dirname = \"X:/Mamede/JM/2020/20200626/igfp1_caruby5_continue001trigger00*.nd2\"\n",
    "#like this format.D:\\Stephanie\\20210702F2\n",
    "dirname = \"./*.nd2\"\n",
    "filelist = glob.glob(dirname)\n",
    "filelist.sort()\n",
    "\n",
    "# filelist = filelist[2:3]\n",
    "# filelist.pop()\n",
    "print(filelist)\n",
    "# print(filelist[1])\n",
    "\n",
    "#Load the first file for reference and what's inside the file\n",
    "frames = ND2Reader(filelist[0])\n",
    "print(frames.sizes)\n",
    "#Grab metadata\n",
    "metadata = frames.metadata\n",
    "print(metadata['channels'])\n",
    "\n",
    "#If you don't have enough VRAM divide the XY to do the deconvolution that is automatically assembled after\n",
    "xdivide = 1\n",
    "ydivide = 1\n",
    "depthdivide = depth_divide(xdivide, ydivide)\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZ_cFKr2hODj",
    "outputId": "e7e51bcc-71da-4c61-d309-b3cd18b77a76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14444444444444468"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metadata['pixel_microns']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VM1A512etcT-",
    "outputId": "d8e85916-1434-4b38-8815-c2fe7034fa9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml = Nd2meta2OMEXML(frames,time_offset=0,maxT=None,verbose=False)\n",
    "xml.image().Pixels.PhysicalSizeZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QODNYDohODj",
    "outputId": "9051c69f-9e58-453c-9f03-6154f885ba0a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#Need to make this a big more automatic, but indexing all the files and iterations is not easy\n",
    "#In the version where the PSF is estimated by flowdec is easier because everything was set to automatic\n",
    "\n",
    "# PSFdir=\"/content/PSF\"\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.3_EMCCD.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.3_EMCCD.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.3_EMCCD.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI_0.3_EMCCD.tif')\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.5_EMCCD.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.5_EMCCD.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.5_EMCCD.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI_0.5_EMCCD.tif')\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647_0.5.tiff\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3_0.5.tiff')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green_0.5.tiff')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI.tif')\n",
    "# psf647 = tf.imread(PSFdir+\"/AF647.tif\")\n",
    "# psfruby =  tf.imread(PSFdir+'/mRuby3.tif')\n",
    "# psfgfp =  tf.imread(PSFdir+'/green.tif')\n",
    "# psfdapi =  tf.imread(PSFdir+'/DAPI.tif')\n",
    "# psfruby = psf647\n",
    "# psfgfp = psf647\n",
    "# psfdapi = psf647\n",
    "    #na = meta['NA']\n",
    "na = 1.4\n",
    "#ra = meta['refractive_index1']\n",
    "ra = 1.5156\n",
    "z = int(frames.sizes['z'])-1\n",
    "# z = 6\n",
    "#     x = frames.sizes['x'] // 2\n",
    "#     y = frames.sizes['y'] // 2\n",
    "#     z = 26\n",
    "x = 256\n",
    "y = 256\n",
    "res_z = xml.image().Pixels.PhysicalSizeZ\n",
    "res_xy =  metadata['pixel_microns']\n",
    "distance_cover = -2\n",
    "##Make better with automatic wavelength from metadata and a loop and a dictionary with the PSFs\n",
    "psf = fd_psf.GibsonLanni(\n",
    "    na = na, wavelength= 0.670 , size_z=  z, size_x=  x , size_y=  y,\n",
    "    m =60, \n",
    "     ns =  1.333,\n",
    "     tg =  170, tg0 = 170,\n",
    "     ni0 =  ra, ti0 = 130,\n",
    "     ni =  ra, \n",
    "     res_lateral =  res_xy , res_axial = res_z, \n",
    "     pz = distance_cover \n",
    ")\n",
    "psf647 = psf.generate()    \n",
    "\n",
    "psf = fd_psf.GibsonLanni(\n",
    "    na = na, wavelength= 0.620, size_z=  z, size_x=  x , size_y=  y,\n",
    "    m =60, \n",
    "     ns =  1.333,\n",
    "     tg =  170, tg0 = 170,\n",
    "     ni0 =  ra, ti0 = 130,\n",
    "     ni =  ra, \n",
    "     res_lateral =  res_xy , res_axial = res_z, \n",
    "     pz = distance_cover \n",
    ")\n",
    "psfruby = psf.generate()\n",
    "\n",
    "psf = fd_psf.GibsonLanni(\n",
    "    na = na, wavelength= 0.535, size_z=  z, size_x=  x , size_y=  y,\n",
    "    m =60, \n",
    "     ns =  1.333,\n",
    "     tg =  170, tg0 = 170,\n",
    "     ni0 =  ra, ti0 = 130,\n",
    "     ni =  ra, \n",
    "     res_lateral =  res_xy , res_axial = res_z, \n",
    "     pz = distance_cover \n",
    ")\n",
    "psfgfp = psf.generate()\n",
    "\n",
    "psf = fd_psf.GibsonLanni(\n",
    "    na = na, wavelength= 0.420, size_z=  z, size_x=  x , size_y=  y,\n",
    "    m =60, \n",
    "     ns =  1.333,\n",
    "     tg =  170, tg0 = 170,\n",
    "     ni0 =  ra, ti0 = 130,\n",
    "     ni =  ra, \n",
    "     res_lateral =  res_xy , res_axial = res_z, \n",
    "     pz = distance_cover \n",
    ")\n",
    "psfdapi = psf.generate()  \n",
    "psf = psfruby\n",
    "#                 )\n",
    "#Clip Top and bottom, I found that if the PSF is calculated with distance from coverslip, it is flipped from Fiji\n",
    "#As in, it is Top to Bottom, I acquire the images Bottom to Top\n",
    "# remove = 13\n",
    "# remove = 14\n",
    "# psf647 = np.flip(psf647,\n",
    "# #                  axis=0\n",
    "#                 )[remove:-remove]\n",
    "\n",
    "# psfgfp = np.flip(psfgfp,\n",
    "# #                  axis=0\n",
    "#                 )[remove:-remove]\n",
    "# psfdapi = np.flip(psfdapi,\n",
    "# #                   axis=0\n",
    "#                  )[remove:-remove]\n",
    "# psfruby = np.flip(psfruby,\n",
    "# #                   axis=0\n",
    "#                  )[remove:-remove]\n",
    "# psf = tf.imread('./Rush/PSF/PSFGL.tif')\n",
    "print(psf.shape)\n",
    "# print(psfruby[22:-22,...].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_1 = np.flip(psf[0:32,...],axis=0)\n",
    "# tf.imsave('./Rush/PSF/pfsflowdec2.tiff',psfgfp)\n",
    "# psf = psfruby[22:-22,...]\n",
    "# psf = psfruby\n",
    "# psf = tf.imread('./Rush/PSF/PSF_GL.tif')\n",
    "# print(psf[28:-28,...].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf[33:65] = psf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "buUeYIaRhODk",
    "outputId": "5b361d73-b433-4a30-c157-df27b288a1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./20210611_E1_cGas_1A11PQBC1_241D_7131.nd2']\n",
      "['./20210611_E1_cGas_1A11PQBC1_241D_7131.nd2']\n"
     ]
    }
   ],
   "source": [
    "algo =init_RL_algo(psfgfp.ndim\n",
    "                   ,pad_mode='2357',pad_min=(2,24,24)\n",
    "#                    ,pad_mode='log2',pad_min=(2,24,24)\n",
    "                  )\n",
    "# from flowdec import restoration as fd_restoration\n",
    "# algo = fd_restoration.RichardsonLucyDeconvolver(n_dims=psfgfp.ndim\n",
    "#                                                     # , pad_mode=pad_mode\n",
    "#                                                     # ,pad_min=pad_min\n",
    "#     #                                                     ,observer_fn=observer\n",
    "#                                                     #,real_domain_fft=True\n",
    "#                                                     #,device='/cpu:0'\n",
    "#                                                    ).initialize()\n",
    "\n",
    "print(filelist)\n",
    "# fname2 = filelist[1]\n",
    "fname1 = filelist[0]\n",
    "# filelist.pop(0)\n",
    "\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "T_dYpmnNhODk"
   },
   "outputs": [],
   "source": [
    "from deco_libraries import update_progress, pimsmeta2OMEXML, Nd2meta2OMEXML, observer, init_RL_algo, deconv, depth_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "VeJoqLWRhODl"
   },
   "outputs": [],
   "source": [
    "\n",
    "# frames.parser._raw_metadata.image_metadata\n",
    "def get_deltaT(filename1,filename2):\n",
    "    \n",
    "    import pathlib\n",
    "#     frames = ND2Reader(filelist[0])\n",
    "#     a = frames.metadata['date']\n",
    "#     frames = ND2Reader(filelist[1])\n",
    "#     b = frames.metadata['date']\n",
    "    fname1 = pathlib.Path(filename1)\n",
    "    fname2 = pathlib.Path(filename2)\n",
    "    import datetime\n",
    "    mtime2 = datetime.datetime.fromtimestamp(fname2.stat().st_ctime)\n",
    "    mtime1 = datetime.datetime.fromtimestamp(fname1.stat().st_ctime)\n",
    "#     print(mtime2,mtime1)\n",
    "#     print(fname2.stat().st_ctime - fname1.stat().st_ctime)\n",
    "    return fname2.stat().st_ctime - fname1.stat().st_ctime\n",
    "    # time_offset = 71146.03463482857\n",
    "# fname2 = filelist[1]\n",
    "# fname1 = filelist[0]   \n",
    "# print(get_deltaT(fname1,fname2)/60)\n",
    "# print(get_deltaT(fname1,fname2)/60)\n",
    "\n",
    "# time_offset = get_deltaT(fname1,fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "K4f8416VhODm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./20210611_E1_cGas_1A11PQBC1_241D_7131.nd2']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filelist.pop(0)\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIPhsieIhODm",
    "outputId": "1addd67a-7fd1-47da-84fc-4c390b4c6eb2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "#these are the settings you need to look at\n",
    "n_iters = 100 # keep this one always at 100\n",
    "\n",
    "savePRJ = True # if you want the projection Z have it at True, if not, False\n",
    "saveStack = True # if you want the Z-stack have it at True, if not, False \n",
    "\n",
    "\n",
    "# time_offset = 0\n",
    "# maxT = 25\n",
    "#do not worry about these ones\n",
    "maxT = None\n",
    "\n",
    "#If it's a broken experiment, you need to do concat Time True, \n",
    "#so that it makes the 0 from file #2 to be the diference between the files\n",
    "concattime = False\n",
    "\n",
    "for fname in filelist:\n",
    "    #to add the real time of experiment when we have to split it into different files\n",
    "    if concattime:\n",
    "#         time_offset = get_deltaT(filelist[0],fname)\n",
    "        time_offset = get_deltaT(fname1,fname)\n",
    "#         time_offset = 72424\n",
    "#         time_offset = 72424\n",
    "    else: time_offset = 0\n",
    "    frames =  ND2Reader(fname)\n",
    "    frames.iter_axes = 't'  # 't' is the default already\n",
    "    frames.bundle_axes = 'zyx'  # when 'z' is available, this will be default\n",
    "\n",
    "    channels = frames.metadata['channels']\n",
    "    metadata = frames.metadata\n",
    "    \n",
    "    if saveStack:\n",
    "        xml = Nd2meta2OMEXML(frames,time_offset=time_offset,maxT=maxT,verbose=False)\n",
    "    if savePRJ:\n",
    "        prjxml = Nd2meta2OMEXML(frames, project=True,time_offset=time_offset,maxT=maxT,verbose=False)\n",
    "\n",
    "    chunk_size=(frames.sizes['z'],frames.sizes['y']//ydivide,frames.sizes['x']//xdivide)\n",
    "\n",
    "    # frames.iter_axes = 'v'\n",
    "    # for frame in frames:\n",
    "#     for visit in range(22,25):\n",
    "#         frames.sizes['v']):\n",
    "#     for visit in range(frames.sizes['v']):\n",
    "    for visit in [0]:\n",
    "\n",
    "        frames.default_coords['v'] = visit\n",
    "        stackfile = fname[:-4]+\"_v\"+str(visit+1).zfill(2)+'.Glani.ome.tiff'\n",
    "        prjfile = fname[:-4]+\"_v\"+str(visit+1).zfill(2)+'_PRJ.Glani.ome.tiff'\n",
    "        if saveStack:\n",
    "            tifstack = tf.TiffWriter(stackfile, bigtiff=False,imagej=False)\n",
    "            firststk = True\n",
    "        if savePRJ:\n",
    "            tifprj = tf.TiffWriter(prjfile, bigtiff=False, imagej=False)\n",
    "            first = True\n",
    "        if maxT == None:\n",
    "            counterT = frames.sizes['t']\n",
    "        else: counterT = maxT\n",
    "# +\n",
    "        for time in range(counterT):\n",
    "#         for time in range(25):\n",
    "\n",
    "#             res = np.zeros(\n",
    "#                 (frames.sizes['z'],frames.sizes['c']\n",
    "#                  ,frames.sizes['y'],frames.sizes['x'])\n",
    "#                 , dtype=np.float32)\n",
    "    \n",
    "            res = np.zeros(\n",
    "                (frames.sizes['z'],frames.sizes['c']\n",
    "                 ,frames.sizes['y'],frames.sizes['x'])\n",
    "                , dtype=np.float32)\n",
    "\n",
    "            for i in range(frames.sizes['c']):\n",
    "#             for i in range(3, frames.sizes['c']):\n",
    "                frames.default_coords['c'] = i\n",
    "#                     print('Channel:',metadata['channels'][i])\n",
    "                ch = metadata['channels'][i]\n",
    "                # ['a647', 'DAPI', 'GFP']\n",
    "                # ['FITC', 'mRuby3', 'miRFP670']\n",
    "                # ['FRET-gYFP-dsRED', 'mRuby', 'GFP', 'DAPI']\n",
    "                # ['a647', 'DAPI', 'GFP']\n",
    "#                 if ch == 'DAPI' or ch  == '470 nm':\n",
    "#                     psf = psfdapi\n",
    "#                 elif ch == 'miRFP670' or ch == 'a647' or ch == 'mirfp670' or ch == 'farRED-EM' or ch == '640 nm':\n",
    "#                     psf = psf647\n",
    "#                 elif ch == 'GFP' or ch == 'FITC'  or ch == 'GREEN-EM' or ch == 'FITC (Em)':\n",
    "#                     psf = psfgfp\n",
    "#                 elif ch == 'mRuby3' or ch == 'mRuby' or ch ==  '555 nm' or ch == 'RED-EM':\n",
    "#                     psf = psfruby\n",
    "#                 elif ch == 'FRET-gYFP-dsRED':\n",
    "#                     psf = psfruby\n",
    "#                 else: \n",
    "                psf = psf\n",
    "\n",
    "                arr = da.from_array(frames[time]           \n",
    "                                    , chunks=chunk_size)\n",
    "\n",
    "                res[:,i,:,:] = da.map_overlap(deconv,arr, depth  = depthdivide ,boundary='reflect',\n",
    "                                    dtype='float32', algo=algo,\n",
    "                                    psf=psf, iters=n_iters, use_ram=False\n",
    "                                             ).compute(num_workers=1)\n",
    "\n",
    "                # If we need to swap Channel and Z in the future\n",
    "                #             img5d = np.swapaxes(img5d,0,1)\n",
    "\n",
    "                update_progress( (visit+1) * (time+1) / (frames.sizes['v']* counterT) )\n",
    "                print(\"Visit Point: {}/{} \\t Time:{}/{} \\t Channel:{}/{}\".format(\n",
    "                        visit+1, frames.sizes['v']\n",
    "                        ,time+1,  counterT\n",
    "                        , i+1, frames.sizes['c']))\n",
    "# Make Function\n",
    "            if saveStack:\n",
    "\n",
    "                if firststk:\n",
    "                    tifstack.save(res.astype(np.uint16),\n",
    "                        compress='ZLIB',\n",
    "                        description = xml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "                    firststk = False\n",
    "                    print('blup')\n",
    "                else:\n",
    "                    tifstack.save(res.astype(np.uint16),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "#                         datetime= True,\n",
    "                        photometric='minisblack',\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "            if savePRJ:\n",
    "                if first:\n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0),\n",
    "                        compress='ZLIB',\n",
    "                        description = prjxml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        #, datetime= True\n",
    "                        metadata= None,\n",
    "                        contiguous=False\n",
    "                        )\n",
    "                    first = False\n",
    "                else:                  \n",
    "                    tifprj.save(res.astype(np.uint16).max(axis=0),\n",
    "                        compress='ZLIB',\n",
    "#                         description = xml.to_xml(),\n",
    "                        photometric='minisblack',\n",
    "                        #, datetime= True\n",
    "                        metadata= None,\n",
    "                        contiguous=False,\n",
    "                        )\n",
    "        if saveStack:\n",
    "            tifstack.close()\n",
    "        if savePRJ:\n",
    "            tifprj.close()\n",
    "\n",
    "    update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPZRi5V-LJSv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-Ndg8pRhODo",
    "outputId": "c3b9f043-f3e7-4a0f-a74c-4adf1f8982c9"
   },
   "outputs": [],
   "source": [
    "print('done')\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "#the memory was released here!\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZtHD7JchODo",
    "outputId": "5edc33a2-ad0c-460d-8dd0-fa8875665790"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmtS1iujhODo"
   },
   "outputs": [],
   "source": [
    "frames =  ND2Reader(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMEAYffEhODp",
    "outputId": "6ec00a54-f9f1-4a0c-ffc3-bc20f3e7e198"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tenf\n",
    "tenf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "u6HfzOJIhODp",
    "outputId": "d37992da-3238-40d7-a1b2-84d1b5140112"
   },
   "outputs": [],
   "source": [
    "import flowdec\n",
    "flowdec.__version__                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOtUXHR6hODp"
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXga-2fRhODp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TRKmLlUhODp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vSO3t_qhODp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Google2021_Deconvolve_Live.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
